set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
predVar <- grep("^IL", names(training))
M0 <- train(training$diagnosis ~ ., data=training[predVar], method="glm")
hat0 <- predict(M0, testing)
confusionMatrix(testing$diagnosis, hat0)
preProc <- preProcess(training[predVar], method="pca", thresh=0.8)
trainPC <- predict(preProc, training[predVar])
M1 <- train(training$diagnosis ~ ., data=trainPC, method="glm")
testPC <- predict(preProc, testing[predVar])
hat1 <- predict(M1, testPC)
confusionMatrix(testing$diagnosis, hat1)
subset = training[,grep("^IL", names(training))]
preProcess(subset, thresh = 0.8, method = "pca")$numComp
trainSubset = training[,grep("^IL", names(training))]
testSubset = testing[,grep("^IL", names(testing))]
pp = preProcess(trainSubset, thresh = 0.8, method = "pca")
trainTransformed <- predict(pp, trainSubset)
testTransformed <- predict(pp, testSubset)
trainSubset$diagnosis = training$diagnosis
testSubset$diagnosis = testing$diagnosis
trainTransformed$diagnosis = training$diagnosis
testTransformed$diagnosis = testing$diagnosis
glmpca = train(diagnosis ~ ., data = trainTransformed, method = "glm")
glm = train(diagnosis ~ ., data = trainSubset, method = "glm")
round(confusionMatrix(testSubset$diagnosis,predict(glm, testSubset))$overall["Accuracy"],2)
round(confusionMatrix(testTransformed$diagnosis,predict(glmpca, testTransformed))$overall["Accuracy"],2)
# Question 2
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
# Make a plot of the outcome (CompressiveStrength) versus the index of the samples.
# Color by each of the variables in the data set (you may find the cut2() function in the Hmisc package useful for turning continuous covariates into factors).
# What do you notice in these plots?
training$index <- seq(1, nrow(training))
require(reshape2)
D <- melt(training, id.var=c("index"))
ggplot(D, aes(x=index, y=value, color=variable)) +
geom_point(alpha=1/2) +
geom_smooth(alpha=1/2) +
facet_wrap(~ variable, nrow=3, scales="free_y") +
theme(legend.position="none")
ggplot(training, aes(x=Cement, y=CompressiveStrength)) +
geom_point(alpha=1/2) +
geom_smooth(alpha=1/2) +
geom_rug(alpha=1/4)
qplot(as.numeric(row.names(concrete)), concrete$CompressiveStrength, colour=concrete$FlyAsh)
View(concrete)
qplot(as.numeric(row.names(concrete)), concrete$CompressiveStrength, colour=concrete$Cement)
qplot(as.numeric(row.names(concrete)), concrete$CompressiveStrength, colour=concrete$BlastFurnaceSlag)
qplot(as.numeric(row.names(concrete)), concrete$CompressiveStrength, colour=concrete$Water)
qplot(as.numeric(row.names(concrete)), concrete$CompressiveStrength, colour=concrete$Superplasticizer)
qplot(as.numeric(row.names(concrete)), concrete$CompressiveStrength, colour=concrete$CoarseAggregate)
qplot(as.numeric(row.names(concrete)), concrete$CompressiveStrength, colour=concrete$FineAggregate)
qplot(as.numeric(row.names(concrete)), concrete$CompressiveStrength, colour=concrete$Age)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
subset = training[,grep("^IL", names(training))]
preProcess(subset, thresh = 0.9, method = "pca")$numComp
subset = training[,grep("^IL", names(training))]
preProcess(subset, thresh = 0.9, method = "pca")$numComp
preProcess(subset,thresh = 0.9,method = "pca")
subset = training[,grep("^IL", names(training))]
preProcess(subset, thresh = 0.8, method = "pca")$numComp
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
subset = training[,grep("^IL", names(training))]
preProcess(subset, thresh = 0.8, method = "pca")$numComp
subset = training[,grep("^IL", names(training))]
preProcess(subset, thresh = 0.9, method = "pca")$numComp
packageVersion(caret)
packageVersion("caret")
install.packages("AppliedPredictiveModeling")
packageVersion("AppliedPredictiveModeling")
install.packages("ElemStatLearn")
packageVersion("pgmm")
install.packages("pgmm")
packageVersion("pgmm")
packageVersion("rpart")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
View(segmentationOriginal)
training = segmentationOriginal[segmentationOriginal$Case == "Train",]
testing = segmentationOriginal[segmentationOriginal$Case == "Test",]
View(testing)
View(training)
set.seed(125)
M <- train(Class ~ ., data=training, method="rpart")
M
M$finalModel
plot(M$finalModel)
text(M$finalModel)
text(M$finalModel)
install.packages("rattle")
library(rattle)
library(rattle)
fancyRpartPlot(M$finalModel)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(M$finalModel)
M$finalModel
plot(M$finalModel)
text(M$finalModel)
M$finalModel
plot(M$finalModel)
text(M$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
M <- train(Area ~ ., data=olive, method="rpart")
newdata = as.data.frame(t(colMeans(olive)))
newdata
predict(M, newdata)
M$finalModel
fancyRpartPlot(M$finalModel)
View(olive)
View(newdata)
newdata$Area <- 10
predict(M,newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
View(trainSA)
M <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA, method="glm", family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, predict(M, testSA))
missClass(trainSA$chd, predict(M, trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
M <- train(y ~ ., data=vowel.train, method="rf")
varImp(M)
View(vowel.test)
debugSource('~/00vehDetect/NN/nn02.R', echo=TRUE)
debugSource('~/00vehDetect/NN/nn02.R', echo=TRUE)
debugSource('~/00vehDetect/NN/nn02.R', echo=TRUE)
debugSource('~/00vehDetect/NN/nn02.R', echo=TRUE)
?predict
?caret::predict
??predict
library(caret)
?predict
?train
debugSource('~/00vehDetect/NN/nn02.R', echo=TRUE)
View(trainSet)
kM <- kmeans(trainset[,-1], centers=5)
kM <- kmeans(trainSet[,-1], centers=5)
kM
kM$cluster
res <- cbind(kM$cluster-1,trainSet[,1])
View(res)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
table(vowel.train$y)
set.seed(33833)
m1 <- train(y~.,data=vowel.train,method="rf")
View(vowel.test)
View(vowel.train)
m2<-train(y~.,data=vowel.train,method="gbm")
hat1<-predict(m1,vowel.test)
hat2<-predict(m2,vowel.test)
confusionMatrix(hat1, vowel.test$y)$overall
confusionMatrix(hat2, vowel.test$y)$overall
hat <- data.frame(hat1,
hat2,
y = vowel.test$y,
agree = hat1 == hat2)
accuracy <- sum(hat1[hat$agree] == hat$y[hat$agree]) / sum(hat$agree)
accuracy
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
table(vowel.train$y)
set.seed(33833)
require(caret)
M1 <- train(y ~ ., data=vowel.train, method="rf")
M2 <- train(y ~ ., data=vowel.train, method="gbm")
hat1 <- predict(M1, vowel.test)
hat2 <- predict(M2, vowel.test)
confusionMatrix(hat1, vowel.test$y)$overall
confusionMatrix(hat2, vowel.test$y)$overall
hat <- data.frame(hat1,
hat2,
y = vowel.test$y,
agree = hat1 == hat2)
accuracy <- sum(hat1[hat$agree] == hat$y[hat$agree]) / sum(hat$agree)
accuracy
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
M1 <- train(diagnosis ~ ., data=training, method="rf")
M2 <- train(diagnosis ~ ., data=training, method="gbm")
M3 <- train(diagnosis ~ ., data=training, method="lda")
hat1 <- predict(M1, testing)
hat2 <- predict(M2, testing)
hat3 <- predict(M3, testing)
hat <- data.frame(hat1, hat2, hat3, diagnosis=testing$diagnosis)
M4 <- train(diagnosis ~ ., data=hat, method="rf")
M4
hat4 <- predict(M4, testing)
confusionMatrix(hat1, testing$diagnosis)$overall
confusionMatrix(hat2, testing$diagnosis)$overall
confusionMatrix(hat3, testing$diagnosis)$overall
confusionMatrix(hat4, testing$diagnosis)$overall
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
M1 <- train(CompressiveStrength ~ ., data=training, method="lasso")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
M1 <- train(CompressiveStrength ~ ., data=training, method="lasso")
M1
plot(M1$finalModel, xvar="penalty")
plot.enet(M1$finalModel, xvar="penalty")
library(lubridate)  # For year() function below
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
dat = read.csv(url)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
require(forecast)
M <- bats(tstrain)
M
hat <- forecast(M, length(testing$visitsTumblr))
hat <- cbind(testing, data.frame(hat))
hat$isIn95 <- hat$Lo.95 < hat$visitsTumblr & hat$visitsTumblr < hat$Hi.95
prop.table(table(hat$isIn95))
View(dat)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
require(e1071)
M <- svm(CompressiveStrength ~ ., data=training)
testing$hat <- predict(M, testing)
testing$error <- testing$CompressiveStrength - testing$hat
rmse <- sqrt(mean(testing$error ^ 2))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
require(e1071)
M <- svm(CompressiveStrength ~ ., data=training)
testing$hat <- predict(M, testing)
testing$error <- testing$CompressiveStrength - testing$hat
rmse <- sqrt(mean(testing$error ^ 2))
rmse
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rf <- train(diagnosis ~ ., data=training, method="rf")
gbm <- train(diagnosis ~ ., data=training, method="gbm")
lda <- train(diagnosis ~ ., data=training, method="lda")
hat1 <- predict(rf, testing)
hat2 <- predict(gbm, testing)
hat3 <- predict(lda, testing)
hat <- data.frame(hat1, hat2, hat3, diagnosis=testing$diagnosis)
rf2 <- train(diagnosis ~ ., data=hat, method="rf")
M4
hat4 <- predict(rf2, testing)
confusionMatrix(hat1, testing$diagnosis)$overall
confusionMatrix(hat2, testing$diagnosis)$overall
confusionMatrix(hat3, testing$diagnosis)$overall
confusionMatrix(hat4, testing$diagnosis)$overall
1.08^30
install.packages("parallel")
library(parallel)
no.cores <- detectCores()-1
no.cores
cl <- makeCluster(no_cores)
cl <- makeCluster(no.cores)
library(doParallel)
cl <- makeCluster(no.cores)
registerDoParallel(cl)
registerDoParallel(cl)
getDoParWorkers()
stopCluster(cl)
getDoParWorkers()
source('C:/Users/mpintor/Dropbox/00R/titanic/trainRF.R', echo=TRUE)
View(trainData)
sapply(trainData[,1:8],class)
View(trainData)
trainData$Survived<-as.factor(trainData$Survived)
sapply(trainData[,1:8],class)
View(trainData)
trCtrl <- trainControl(method = "cv", number = 5)
rfTitanic <- train(classe ~., data=trainData, method = "rf", trControl = trCtrl)
rfTitanic <- train(Survived ~., data=trainData, method = "rf", trControl = trCtrl)
rfTitanic <- train(Survived ~., data=trainData, method = "rf", trControl = trCtrl)
cl
rfTitanic <- train(Survived ~., data=trainData, method = "rf", trControl = trCtrl)
registerDoSEQ()
rfTitanic <- train(Survived ~., data=trainData, method = "rf", trControl = trCtrl)
rfTitanic
confusionMatrix(rfTitanic)
trCtrl <- trainControl(method = "repeatedcv", number = 5, repeats = 5)
rfTitanic <- train(Survived ~., data=trainData, method = "rf", trControl = trCtrl)
rfTitanic
confusionMatrix(rfTitanic)
trCtrl <- trainControl(method = "cv", number = 5)
rfTitanic <- train(Survived ~., data=trainData, method = "rf", trControl = trCtrl)
confusionMatrix(rfTitanic)
?train
lrTitanic <- train(Survived ~., data=trainData, method = "logreg", trControl = trCtrl)
lrTitanic <- train(Survived ~., data=trainData, method = "logreg", trControl = trCtrl)
lrTitanic <- train(Survived ~., data=trainData, method = "binda", trControl = trCtrl)
lrTitanic <- train(Survived ~., data=trainData, method = "deepboost", trControl = trCtrl)
lrTitanic <- train(Survived ~., data=trainData, method = "rf", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "LogitBoost", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "LogitBoost", trControl = trCtrl)
Titanic
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "BstLm", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "deepboost", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "gbm", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "bayesglm", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "glmboost", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "glmboost", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "glmStepAIC", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "glmnet", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "glmnet", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "adaboost", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "binda", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "ada", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "glmboost", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "deepboost", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "glmStepAIC", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "ORFpls", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "svmRadialWeights", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "lssvmLinear", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "lssvmPoly", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "svmLinear", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "rocc", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "rvmLinear", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "rmda", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "extraTrees", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "parRF", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "qrf", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "rFerns", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "ranger", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "extraTrees", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "Boruta", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "RRFglobal", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "LMT", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "ORFlog", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "ORFridge", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "ORFsvm", trControl = trCtrl)
Titanic <- train(Survived ~., data=trainData, method = "elm", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "mlp", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "nnet", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic
Titanic <- train(Survived ~., data=trainData, method = "dnn", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic
confusionMatrix(Titanic)
Titanic
Titanic <- train(Survived ~., data=trainData, method = "rpartCost", trControl = trCtrl)
Titanic
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "treebag", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic <- train(Survived ~., data=trainData, method = "gaussprPoly", trControl = trCtrl)
confusionMatrix(Titanic)
Titanic
Titanic <- train(Survived ~., data=trainData, method = "AdaBoost.M1", trControl = trCtrl)
confusionMatrix(Titanic)
orTraining <- read.csv("data/pml-training.csv")
orTesting <- read.csv("data/pml-testing.csv")
dim(orTraining)
dim(orTesting)
setwd("C:/Users/mpintor/Documents/00educa/coursera/data science/08 Practical Machine Learning/project")
library(knitr); library(rattle); library(caret); library(corrplot); library(parallel); library(doParallel)
orTraining <- read.csv("data/pml-training.csv")
orTesting <- read.csv("data/pml-testing.csv")
dim(orTraining)
dim(orTesting)
clases <- sapply(orTraining[,1:160], class)
table(clases)
# subset columns for features
trainFeatures <- orTraining[,8:159]
testFeatures <- orTesting[,8:159]
# coerce factors to numeric
for(i in seq(1, dim(trainFeatures)[2])){
if(is.factor(trainFeatures[,i])){
trainFeatures[,i] <- as.numeric(as.character(trainFeatures[,i]))
testFeatures[,i] <- as.numeric(as.character(testFeatures[,i]))
}
}
# NAs to zero
trainFeatures[is.na(trainFeatures)] <- 0
testFeatures[is.na(testFeatures)] <- 0
# near zero variance features remotion
nzv <- nearZeroVar(trainFeatures)
trainFeatures <- trainFeatures[,-nzv]
testFeatures <- testFeatures[,-nzv]
# subset columns for features
trainFeatures <- orTraining[,8:159]
testFeatures <- orTesting[,8:159]
# coerce factors to numeric
for(i in seq(1, dim(trainFeatures)[2])){
if(is.factor(trainFeatures[,i])){
trainFeatures[,i] <- as.numeric(as.character(trainFeatures[,i]))
testFeatures[,i] <- as.numeric(as.character(testFeatures[,i]))
}
}
# NAs to zero
trainFeatures[is.na(trainFeatures)] <- 0
testFeatures[is.na(testFeatures)] <- 0
# near zero variance features remotion
nzv <- nearZeroVar(trainFeatures)
trainFeatures <- trainFeatures[,-nzv]
testFeatures <- testFeatures[,-nzv]
corMatrix <- cor(trainFeatures)
corrplot(corMatrix, method="circle", tl.cex = .5, type = "lower")
class(corMatrix)
corFeatures <- findCorrelation(corMatrix)
testFeatures <- testFeatures[, -corFeatures]
trainFeatures <- trainFeatures[, -corFeatures]
train <- cbind(classe = orTraining$classe, trainFeatures)
set.seed(2302)
trCtrl <- trainControl(method = "cv", number = 5)
rfModel <- train(classe ~., data=train, method = "rf", trControl = trCtrl)
rfModel$finalModel
varImpPlot(rfModel$finalModel, type=2)
plot(rfModel$finalModel)
confusionMatrix(rfModel$finalModel)
pred <- predict(rfModel$finalModel, train)
confusionMatrix(pred, train$classe)
